"""
microgpt - A comprehensive, pure-Python GPT ecosystem.

This package provides a complete implementation of GPT (Generative
Pre-trained Transformer) with state-of-the-art features.

This is the root package entry point. All modules are now organized
under the microgpt/ directory for proper Python package structure.
"""

# Re-export from the microgpt package for backward compatibility
from microgpt import (
    GPT,
    Value,
    Trainer,
    AdamOptimizer,
    LRScheduler,
    CharTokenizer,
    DataLoader,
    BPETokenizer,
    preprocess_text,
    Config,
    ModelConfig,
    TrainingConfig,
    GenerationConfig,
    CheckpointManager,
    TrainingLogger,
    Metrics,
    BeamSearchDecoder,
    ContrastiveSearchDecoder,
    RepetitionPenaltyLogitsProcessor,
    QuantizedGPT,
    quantize_model,
    ModernGPT,
    RoPE,
    SwiGLU,
    ALiBi,
    LionOptimizer,
    SophiaOptimizer,
    MuonOptimizer,
    CurriculumLearning,
    MixtureOfExperts,
    RLHFTrainer,
    DPOTrainer,
    ConstitutionalAI,
    SafetyClassifier,
    Watermarking,
    VisionEncoder,
    AudioEncoder,
    MultiModalGPT,
    ToolUse,
    RAG,
    PagedAttention,
    ContinuousBatching,
    SpeculativeDecodingEngine,
    StreamingLLM,
    LoRA,
    QLoRA,
    DoRA,
    ReLoRA,
    GaLore,
    MambaBlock,
    GriffinBlock,
    JambaArchitecture,
    DiffTransformer,
    TitansArchitecture,
    TIESMerging,
    DARE,
    ModelSoups,
    TaskArithmetic,
    SLERP,
    PerplexityMetrics,
    BLEU,
    ROUGE,
    ComprehensiveEvaluator,
    ChainOfThought,
    TreeOfThought,
    ReAct,
    Reflexion,
    SelfConsistency,
    Agent,
    MultiAgentSystem,
    Planner,
    Profiler,
    ModelAnalyzer,
    SpeedBenchmark,
    MagnitudePruning,
    KnowledgeDistillation,
    create_model,
    list_models,
    create_tokenizer,
    __version__,
    __author__,
    __license__,
)

__all__ = [
    "GPT",
    "Value",
    "Trainer",
    "AdamOptimizer",
    "LRScheduler",
    "CharTokenizer",
    "DataLoader",
    "BPETokenizer",
    "preprocess_text",
    "Config",
    "ModelConfig",
    "TrainingConfig",
    "GenerationConfig",
    "CheckpointManager",
    "TrainingLogger",
    "Metrics",
    "BeamSearchDecoder",
    "ContrastiveSearchDecoder",
    "RepetitionPenaltyLogitsProcessor",
    "QuantizedGPT",
    "quantize_model",
    "ModernGPT",
    "RoPE",
    "SwiGLU",
    "ALiBi",
    "LionOptimizer",
    "SophiaOptimizer",
    "MuonOptimizer",
    "CurriculumLearning",
    "MixtureOfExperts",
    "RLHFTrainer",
    "DPOTrainer",
    "ConstitutionalAI",
    "SafetyClassifier",
    "Watermarking",
    "VisionEncoder",
    "AudioEncoder",
    "MultiModalGPT",
    "ToolUse",
    "RAG",
    "PagedAttention",
    "ContinuousBatching",
    "SpeculativeDecodingEngine",
    "StreamingLLM",
    "LoRA",
    "QLoRA",
    "DoRA",
    "ReLoRA",
    "GaLore",
    "MambaBlock",
    "GriffinBlock",
    "JambaArchitecture",
    "DiffTransformer",
    "TitansArchitecture",
    "TIESMerging",
    "DARE",
    "ModelSoups",
    "TaskArithmetic",
    "SLERP",
    "PerplexityMetrics",
    "BLEU",
    "ROUGE",
    "ComprehensiveEvaluator",
    "ChainOfThought",
    "TreeOfThought",
    "ReAct",
    "Reflexion",
    "SelfConsistency",
    "Agent",
    "MultiAgentSystem",
    "Planner",
    "Profiler",
    "ModelAnalyzer",
    "SpeedBenchmark",
    "MagnitudePruning",
    "KnowledgeDistillation",
    "create_model",
    "list_models",
    "create_tokenizer",
    "__version__",
    "__author__",
    "__license__",
]
